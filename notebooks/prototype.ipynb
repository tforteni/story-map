{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f2c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callahan GPE\n",
      "Rivenfell ORG\n",
      "30 days DATE\n",
      "a week DATE\n",
      "Mizani GPE\n",
      "Lok PERSON\n",
      "a week DATE\n"
     ]
    }
   ],
   "source": [
    "# Testing python's more primitive spacy\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "texts = [\"The group travelled from Callahan to Rivenfell on foot in 30 days.\", \n",
    "\"He went up north to Erendale by horse in a week\",\n",
    "\"He went from Ayo to Mizani to Lok in a week\"]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 50 files:   0%|          | 0/50 [05:32<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# This times out\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# # choose the model you want\n",
    "# model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "# # load tokenizer + model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     device_map=\"auto\",   # put on GPU if available\n",
    "#     torch_dtype=\"auto\"   # use float16 if GPU supports it\n",
    "# )\n",
    "\n",
    "# # create a text-generation pipeline\n",
    "# generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# # test it\n",
    "# prompt = \"The group travelled from Callahan to Rivenfell on foot in 30 days.\"\n",
    "# output = generator(prompt, max_new_tokens=100, do_sample=True)\n",
    "# print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fde500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'LOC', 'score': 0.9534046, 'word': 'Callahan', 'start': 25, 'end': 33}, {'entity_group': 'LOC', 'score': 0.8274439, 'word': 'Rivenfell', 'start': 37, 'end': 46}], [{'entity_group': 'LOC', 'score': 0.88226366, 'word': 'Erendale', 'start': 20, 'end': 28}], [{'entity_group': 'LOC', 'score': 0.8103365, 'word': 'Ayo', 'start': 13, 'end': 16}, {'entity_group': 'LOC', 'score': 0.92976063, 'word': 'Mizani', 'start': 20, 'end': 26}, {'entity_group': 'LOC', 'score': 0.9276268, 'word': 'Lok', 'start': 30, 'end': 33}]]\n",
      "[['Callahan', 'Rivenfell'], ['Erendale'], ['Ayo', 'Mizani', 'Lok']]\n"
     ]
    }
   ],
   "source": [
    "#Testing NER\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "texts = [\"The group travelled from Callahan to Rivenfell on foot in 30 days.\", \n",
    "\"He went up north to Erendale by horse in a week\",\n",
    "\"He went from Ayo to Mizani to Lok in a week\"]\n",
    "\n",
    "more_complex_texts = [\"The group travelled from Rivenfell to Callahan in 30 days on foot. The group then travelled from Callahan to Rivenfell in 1 day on foot.\", \n",
    "\"The party travelled north from Erendale to Camelot in 30 days on foot\",\n",
    "\"He travelled north from Rivenfell to Callahan and then went east to Camelot in 50 days on foot.\", \n",
    "\"The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan and then went east to Camelot in 50 days on foot.\", \n",
    "\"The group travelled north from Rivenfell to Callahan. While in Callahan, they acquired a traveller’s guide and learnt that the journey from Erendale to Camelot took ten days on horseback\"]\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json={\"inputs\": texts})\n",
    "entities_per_text = response.json()\n",
    "print(entities_per_text)\n",
    "\n",
    "# Extract only locations from each text\n",
    "locations_list = []\n",
    "for entities in entities_per_text:\n",
    "    locs = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "    locations_list.append(locs)\n",
    "\n",
    "print(locations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a6cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Rivenfell', 'Callahan', 'Callahan', 'Rivenfell'], ['Erendale', 'Camelot'], ['Rivenfell', 'Callahan', 'Camelot'], ['Erendale', 'Camelot', 'Rivenfell', 'Callahan', 'Camelot'], ['Rivenfell', 'Callahan', 'Callahan', 'Erendale', 'Camelot']]\n"
     ]
    }
   ],
   "source": [
    "#Testing NER\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "more_complex_texts = [\"The group travelled from Rivenfell to Callahan in 30 days on foot. The group then travelled from Callahan to Rivenfell in 1 day on foot.\", \n",
    "\"The party travelled north from Erendale to Camelot in 30 days on foot\",\n",
    "\"He travelled north from Rivenfell to Callahan and then went east to Camelot in 50 days on foot.\", \n",
    "\"The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan and then went east to Camelot in 50 days on foot.\", \n",
    "\"The group travelled north from Rivenfell to Callahan. While in Callahan, they acquired a traveller’s guide and learnt that the journey from Erendale to Camelot took ten days on horseback\"]\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json={\"inputs\": more_complex_texts})\n",
    "entities_per_text = response.json()\n",
    "\n",
    "locations_list2 = []\n",
    "for entities in entities_per_text:\n",
    "    locs = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "    locations_list2.append(locs)\n",
    "\n",
    "print(locations_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1bac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'LOC', 'score': np.float32(0.95907587), 'word': 'Callahan', 'start': 25, 'end': 33}, {'entity_group': 'LOC', 'score': np.float32(0.85557777), 'word': 'Rivenfell', 'start': 37, 'end': 46}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"The group travelled from Callahan to Rivenfell on foot in 30 days.\"\n",
    "entities = ner(text)\n",
    "print(entities)\n",
    "\n",
    "locations_list = []\n",
    "for entities in entities_per_text:\n",
    "    locs = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "    locations_list.append(locs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd32066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Callahan', 'Rivenfell'], ['Erendale'], ['Ayo', 'Mizani', 'Lok']]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "text = \"The group travelled from Callahan to Rivenfell on foot in 30 days.\"\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "locations_list = []\n",
    "for entities in entities_per_text:\n",
    "    locs = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "    locations_list.append(locs)\n",
    "print(locations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afc472a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The group travelled from Callahan to Rivenfell on foot in 30 days.\n",
      "Locations: ['Callahan', 'Rivenfell']\n",
      "Dates: ['30 days']\n",
      "\n",
      "Text: He went up north to Erendale by horse in a week\n",
      "Locations: ['Erendale']\n",
      "Dates: ['a week']\n",
      "\n",
      "Text: He went from Ayo to Mizani to Lok in a week\n",
      "Locations: ['Ayo', 'Mizani', 'Lok']\n",
      "Dates: ['a week']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import spacy\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "texts = [\"The group travelled from Callahan to Rivenfell on foot in 30 days.\",\n",
    "\"He went up north to Erendale by horse in a week\",\n",
    "\"He went from Ayo to Mizani to Lok in a week\"]\n",
    "\n",
    "for text in texts:\n",
    "    entities = ner_pipeline(text)\n",
    "\n",
    "    locations = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "\n",
    "    doc = nlp(text)\n",
    "    # Filter only DATE or TIME entities\n",
    "    date_entities = [ent.text for ent in doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Locations: {locations}\")\n",
    "    print(f\"Dates: {date_entities}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: The group travelled from Callahan to Rivenfell on foot in 30 days.\n",
      "Locations: ['Callahan', 'Rivenfell']\n",
      "Dates: ['30 days']\n",
      "\n",
      "Text: He went up north to Erendale by horse in a week\n",
      "Locations: ['Erendale']\n",
      "Dates: ['a week']\n",
      "\n",
      "Text: He went from Ayo to Mizani to Lok in a week\n",
      "Locations: ['Ayo', 'Mizani', 'Lok']\n",
      "Dates: ['a week']\n",
      "\n",
      "Text: The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan.\n",
      "Locations: ['Erendale', 'Camelot']\n",
      "Dates: ['30 days']\n",
      "\n",
      "Text: The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan.\n",
      "Locations: ['Rivenfell', 'Callahan']\n",
      "Dates: []\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import spacy\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "texts = [\"The group travelled from Callahan to Rivenfell on foot in 30 days.\",\n",
    "\"He went up north to Erendale by horse in a week\",\n",
    "\"He went from Ayo to Mizani to Lok in a week\",\n",
    "\"The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan.\"]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        sentence_text = sent.text\n",
    "        entities = ner_pipeline(sentence_text)\n",
    "\n",
    "        locations = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "\n",
    "        sent_doc = nlp(sentence_text)\n",
    "\n",
    "        date_entities = [ent.text for ent in sent_doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"Locations: {locations}\")\n",
    "        print(f\"Dates: {date_entities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c972eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: The group travelled from Callahan to Rivenfell on foot in 30 days.\n",
      "Locations: ['Callahan', 'Rivenfell']\n",
      "Dates: ['30 days']\n",
      "\n",
      "Text: He went up north to Erendale by horse in a week.\n",
      "Locations: ['Erendale']\n",
      "Dates: ['a week']\n",
      "\n",
      "Text: He went from Ayo to Mizani to Lok in a week.\n",
      "Locations: ['Ayo', 'Mizani', 'Lok']\n",
      "Dates: ['a week']\n",
      "\n",
      "Text: The party travelled north from Erendale to Camelot in 30 days on foot.\n",
      "Locations: ['Erendale', 'Camelot']\n",
      "Dates: ['30 days']\n",
      "\n",
      "Text: He travelled north from Rivenfell to Callahan.\n",
      "Locations: ['Rivenfell', 'Callahan']\n",
      "Dates: []\n",
      "[{'locations': ['Callahan', 'Rivenfell'], 'date': ['30 days']}, {'locations': ['Erendale'], 'date': ['a week']}, {'locations': ['Ayo', 'Mizani', 'Lok'], 'date': ['a week']}, {'locations': ['Erendale', 'Camelot'], 'date': ['30 days']}, {'locations': ['Rivenfell', 'Callahan'], 'date': []}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, logging\n",
    "import spacy\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "text = \"The group travelled from Callahan to Rivenfell on foot in 30 days. He went up north to Erendale by horse in a week. He went from Ayo to Mizani to Lok in a week. The party travelled north from Erendale to Camelot in 30 days on foot. He travelled north from Rivenfell to Callahan.\"\n",
    "\n",
    "def get_all_travel_info(paragraph: str):\n",
    "    all_info = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    ner = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "        aggregation_strategy=\"simple\"\n",
    "    )\n",
    "\n",
    "    doc = nlp(paragraph)\n",
    "    all_info = [extract_travel_info(sent.text, nlp, ner) for sent in doc.sents]\n",
    "    return all_info\n",
    "\n",
    "def extract_travel_info(text, nlp, ner) -> dict:\n",
    "    info = {}\n",
    "\n",
    "    entities = ner(text)\n",
    "\n",
    "    info[\"locations\"] = [ent[\"word\"] for ent in entities if ent.get(\"entity_group\") == \"LOC\"]\n",
    "\n",
    "    sent_doc = nlp(text)\n",
    "\n",
    "    info[\"date\"] = [ent.text for ent in sent_doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Locations: {info[\"locations\"]}\")\n",
    "    print(f\"Dates: {info[\"date\"]}\")\n",
    "    return info\n",
    "\n",
    "print(get_all_travel_info(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
